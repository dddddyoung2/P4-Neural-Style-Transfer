# Art Filter: 원하는 스타일로 이미지 변환하기
### 딥러닝의 Neural-Style-Transfer 방식 사용


### 주제 선정 이유 
- 딥러닝, 엔터테인먼트 산업 관심 
- 이미지 변환은 엔터 산업의 중요한 요소
- 이미지 변환의 작동 원리를 알아보고자 함


책 참고: 케라스 창시자에게 배우는 딥러닝
### Neural Style Transfer
- 2015년 리온 게티스가 발표한 알고리즘
- 변환하고 싶은 나의 이미지를 보존하면서 원하는 이미지의 스타일을 나의 이미지에 적용하는 것
- 스타일이란 질감, 색깔, 이미지에 있는 다양한 크기의 시각 요소를 의미

![image](https://user-images.githubusercontent.com/79177935/124305637-56a77f00-dba0-11eb-8841-e84997d04469.png)

- 알고리즘 구현의 핵심 개념: 목표를 표현한 손실 함수를 정의하고 이 손실을 최소화하고, 참조 이미지의 스타일을 적용하면서 원본 이미지의 콘텐츠를 보존할 수 있도록 함


### 단 2장의 이미지로 어느 정도까지 수행할 수 있을까?

가설: 스타일 이미지의 색감과 구도는 이미지 변환에 영향을 줄 것이다.

Check!(확인 해 볼 것)
1. 이미지 반복 학습에 따른 변화 비교
2. content image의 요소(배경, 인물)에 따른 변환 비교
3. 전혀 다른 스타일의 이미지도 변환이 가능한가?
4. 애니메이션 스타일 이미지로 변환이 가능한가?


------------------------------------------------


### 구현 단계
개발 환경: google colab, keras사용
(Neural_Style_Transfer.ipynb 의 코드를 따라하면 됩니다)

1. 데이터셋 & 이미지 전처리
- 원하는 데이터를 모으고, 파일 업로드 함수를 사용해 이미지의 경로를 설정해 줍니다.
- 픽셀을 조정합니다.
2. VGG19 네트워크 설정
3. 손실 함수 정의
(콘텐츠 손실, 스타일 손실, 손실함수 추가)
4. 경사 하강법 단계 설정
5. Iteration(반복)

(참고)
![image](https://user-images.githubusercontent.com/79177935/124306526-7be8bd00-dba1-11eb-90b7-39b59420944b.png)


------------------------------------------------


### 구현 결과

![image](https://user-images.githubusercontent.com/79177935/124306579-91f67d80-dba1-11eb-9564-49fa8176a786.png)
- 원래 이미지의 전체적인 느낌을 보존할 수 있는 이유는 콘텐츠 손실을 정의할 때, 네트워크의 하나의 상위 층만 사용했기 때문
- 네트워크의 상위 층은 이미지의 전체적인 추상적 정보를 담고 있기에 상위층만 ㅇ사용해 콘텐츠 이미지를 보존할 수 있는 것.

1. 이미지 반복 학습에 따른 변화 비교
![image](https://user-images.githubusercontent.com/79177935/124306853-eef23380-dba1-11eb-80cd-ce83ff1c7850.png)
- 미세하지만 100번 반복했을 때가 앤디워홀의 그림체와 더 가까워지는 것을 볼 수 있다.

![image](https://user-images.githubusercontent.com/79177935/124306958-11844c80-dba2-11eb-98db-c36db02efa76.png)

2. content image의 요소(배경, 인물)에 따른 변환 비교
![image](https://user-images.githubusercontent.com/79177935/124307159-5f00b980-dba2-11eb-8094-20dfd3afcfe4.png)
![image](https://user-images.githubusercontent.com/79177935/124307286-940d0c00-dba2-11eb-8a65-538784c1a9e2.png)

- 배경 이미지를 변환했을 때 조금 더 뚜렷하게 표현되는 것을 볼 수 있습니다.
- 큰 차이는 없지만, content image가 인물보다는 배경일 때 더 잘 표현됐다.
(content_weigh가 높을 때, 결과 이미지에 content_image가 더 잘 나타났다.)
(하이퍼 파라미터를 수정하면 성능을 올릴 수 있을 수도 있다.)


3. 전혀 다른 스타일의 이미지도 변환이 가능한가?
![image](https://user-images.githubusercontent.com/79177935/124307308-9ec7a100-dba2-11eb-9e69-ffcb17892f5d.png)
- 변환이 가능하지만, 색감이 너무 다르다면, 원본 사진을 못 알아볼 정도의 결과가 나타났다.


4. 애니메이션 스타일 이미지로 변환이 가능한가?
![image](https://user-images.githubusercontent.com/79177935/124307401-bef76000-dba2-11eb-81e3-a7ee08fe7509.png)
- : 한 장의 스타일 이미지로는 적절하지 않다고 판단한다.


------------------------------------------------


결론
Neural Style Transfer 
- 장점: 이미지 2장(content image & style image)으로 style transfer가 가능하다.
- 단점: 매번 이미지를 새롭게 최적화 해야 하므로 시간이 오래 걸린다.


- > 이미지 한장으로 어느 정도는 가능하나, 드라마틱하고 정교한 변환은 어려움
- > 프리즈마 어플처럼 정교하게 수행되려면 파라미터에 대한 깊은 이해가 필요할 것으로 보임



